{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5373f9a0-efd6-49bd-af99-ddafd3be85e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e40b8b0-0efd-43ba-b027-6519e8ee33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = ''\n",
    "for file in os.listdir():\n",
    "    if file.endswith(\".txt\"):\n",
    "        with open(file, 'r', encoding=\"cp1251\") as f:\n",
    "            text = f.read()\n",
    "            txt += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6730f84c-0f7c-418b-aef9-f87aa765c113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6723492"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d046fc-c140-4652-9916-4673b7fa3110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\n",
      " !\"#&'()*,-./0123456789:;?@ABCDEFGHIJKLMNOPQRSTUVWXZ[]_abcdefghijklmnopqrstuvwxyz «»ІАБВГДЕЖЗИКЛМНОПРСТУФХЦЧШЩЪЬЭЮЯабвгдежзийклмнопрстуфхцчшщъыьэюяёїќ–—’“”„…№\n",
      "160\n"
     ]
    }
   ],
   "source": [
    "##Уникальные символы Достоевского\n",
    "chars = sorted(list(set(txt)))\n",
    "vocab_size=len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2263a4f3-b11b-4531-a462-0779f5bda42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##char level tokenizer\n",
    "stoi = { ch:i for i, ch in enumerate(chars)}\n",
    "itos = { i:ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[c] for c in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c79114b-0bda-44ed-b819-a04a7d3d84ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6723492]) torch.int64\n",
      "tensor([109,  87, 103, 104, 113,   2, 101,  92, 102,  89,  87, 116,   1,   1,\n",
      "          1,   1,  90, 128, 117, 119, 117,   2, 132, 122, 133, 119, 117, 148,\n",
      "          1,   1,   1,   1,  37,   1,   1,  99, 122,   2, 136, 135, 122, 133,\n",
      "        132, 122, 119,  11,   2, 148,   2, 134, 122, 128,   2, 124, 117, 132,\n",
      "        125, 134, 144, 119, 117, 135, 145,   2, 146, 135, 136,   2, 125, 134,\n",
      "        135, 131, 133, 125, 147,   2, 129, 131, 125, 138,   2, 132, 122, 133,\n",
      "        119, 144, 138,   2, 141, 117, 120, 131, 119,   2, 130, 117,   2, 123,\n",
      "        125, 124, 130, 122, 130, 130, 131, 129,   2, 132, 131, 132, 133, 125,\n",
      "        142, 122,  11,   2, 135, 131, 120, 121, 117,   2, 127, 117, 127,   2,\n",
      "        129, 131, 120,   2, 118, 144,   2, 131, 118, 131, 126, 135, 125, 134,\n",
      "        145,   2, 125,   2, 118, 122, 124,   2, 135, 131, 120, 131,  13,   2,\n",
      "        100, 121, 130, 131,   2, 124, 130, 117, 147,   2, 130, 117, 119, 122,\n",
      "        133, 130, 131,  25,   2, 130, 125, 127, 131, 120, 121, 117,   2, 136,\n",
      "        123, 122,   2, 118, 131, 128, 122, 122,   2, 130, 122,   2, 134, 148,\n",
      "        121, 136,   2, 132, 125, 134, 117, 135, 145,   2, 129, 131, 147,   2,\n",
      "        117, 119, 135, 131, 118, 125, 131, 120, 133, 117, 137, 125, 147,  11,\n",
      "          2, 121, 117, 123, 122,   2, 122, 134, 128, 125,   2, 132, 133, 131,\n",
      "        123, 125, 119, 136,   2, 121, 131,   2, 134, 135, 117,   2, 128, 122,\n",
      "        135,  13,   2,  99, 117, 121, 131,   2, 118, 144, 135, 145,   2, 134,\n",
      "        128, 125, 141, 127, 131, 129,   2, 132, 131, 121, 128, 131,   2, 119,\n",
      "        128, 147, 118, 128, 122, 130, 130, 144, 129,   2, 119,   2, 134, 122,\n",
      "        118, 148,  11,   2, 140, 135, 131, 118, 144,   2, 132, 125, 134, 117,\n",
      "        135, 145,   2, 118, 122, 124,   2, 134, 135, 144, 121, 117,   2, 131,\n",
      "          2, 134, 117, 129, 131, 129,   2, 134, 122, 118, 122,  13,   2, 104,\n",
      "        122, 129,   2, 135, 131, 128, 145, 127, 131,   2, 134, 122, 118, 148,\n",
      "          2, 125, 124, 119, 125, 130, 148, 147,  11,   2, 140, 135, 131,   2,\n",
      "        130, 122,   2, 121, 128, 148,   2, 135, 131, 120, 131,   2, 132, 125,\n",
      "        141, 136,  11,   2, 121, 128, 148,   2, 140, 122, 120, 131,   2, 119,\n",
      "        134, 122,   2, 132, 125, 141, 136, 135,  11,   2, 135, 131,   2, 122,\n",
      "        134, 135, 145,   2, 130, 122,   2, 121, 128, 148,   2, 132, 131, 138,\n",
      "        119, 117, 128,   2, 140, 125, 135, 117, 135, 122, 128, 148,  13,   2,\n",
      "         92, 134, 128, 125,   2, 148,   2, 119, 121, 133, 136, 120,   2, 119,\n",
      "        124, 121, 136, 129, 117, 128,   2, 124, 117, 132, 125, 134, 117, 135,\n",
      "        145,   2, 134, 128, 131, 119, 131,   2, 119,   2, 134, 128, 131, 119,\n",
      "        131,   2, 119, 134, 122,  11,   2, 140, 135, 131,   2, 134, 128, 136,\n",
      "        140, 125, 128, 131, 134, 145,   2, 134, 131,   2, 129, 130, 131, 126,\n",
      "          2, 134,   2, 132, 133, 131, 141, 128, 131, 120, 131,   2, 120, 131,\n",
      "        121, 117,  11,   2, 135, 131,   2, 119, 124, 121, 136, 129, 117, 128,\n",
      "          2, 146, 135, 131,   2, 119, 134, 128, 122, 121, 134, 135, 119, 125,\n",
      "        122,   2, 119, 130, 136, 135, 133, 122, 130, 130, 122, 126,   2, 132,\n",
      "        131, 135, 133, 122, 118, 130, 131, 134, 135, 125,  25,   2, 121, 131,\n",
      "          2, 135, 131, 120, 131,   2, 148,   2, 132, 131, 133, 117, 123, 122,\n",
      "        130,   2, 119, 134, 122, 129,   2, 134, 131, 119, 122, 133, 141, 125,\n",
      "        119, 141, 125, 129, 134, 148,  13,   2, 116,   2, 124, 117, 132, 125,\n",
      "        134, 144, 119, 117, 147,   2, 128, 125, 141, 145,   2, 134, 131, 118,\n",
      "        144, 135, 125, 148,  11,   2, 136, 127, 128, 131, 130, 148, 148, 134,\n",
      "        145,   2, 119, 134, 122, 129, 125,   2, 134, 125, 128, 117, 129, 125,\n",
      "          2, 131, 135,   2, 119, 134, 122, 120, 131,   2, 132, 131, 134, 135,\n",
      "        131, 133, 131, 130, 130, 122, 120, 131,  11,   2, 117,   2, 120, 128,\n",
      "        117, 119, 130, 131, 122,   2, 153,   2, 131, 135,   2, 128, 125, 135,\n",
      "        122, 133, 117, 135, 136, 133, 130, 144, 138,   2, 127, 133, 117, 134,\n",
      "        131, 135,  26,   2, 128, 125, 135, 122, 133, 117, 135, 131, 133,   2,\n",
      "        132, 125, 141, 122, 135,   2, 135, 133, 125, 121, 139, 117, 135, 145,\n",
      "          2, 128, 122, 135,   2, 125,   2, 119,   2, 127, 131, 130, 139, 122,\n",
      "          2, 134, 131, 119, 134, 122, 129,   2, 130, 122,   2, 124, 130, 117,\n",
      "        122, 135,  11,   2, 121, 128, 148,   2, 140, 122, 120, 131,   2, 131,\n",
      "        130,   2, 132, 125, 134, 117, 128,   2, 134, 135, 131, 128, 145, 127,\n",
      "        131,   2, 128, 122, 135,  13,   2, 116,   2, 153,   2, 130, 122,   2,\n",
      "        128, 125, 135, 122, 133, 117, 135, 131, 133,  11,   2, 128, 125, 135,\n",
      "        122, 133, 117, 135, 131, 133, 131, 129,   2, 118, 144, 135, 145,   2,\n",
      "        130, 122,   2, 138, 131, 140, 136,   2, 125,   2, 135, 117, 142, 125,\n",
      "        135, 145,   2, 119, 130, 136, 135, 133, 122, 130, 130, 131, 134, 135,\n",
      "        145,   2, 121, 136, 141, 125,   2, 129, 131, 122, 126,   2, 125,   2,\n",
      "        127, 133, 117, 134, 125, 119, 131, 122,   2, 131, 132, 125, 134, 117,\n",
      "        130, 125, 122,   2, 140, 136, 119, 134, 135, 119,   2, 130, 117,   2,\n",
      "        125, 138,   2, 128, 125, 135, 122, 133, 117, 135, 136, 133, 130, 144,\n",
      "        126,   2, 133, 144, 130, 131, 127,   2, 132, 131, 140, 122, 128,   2,\n",
      "        118, 144,   2, 130, 122, 132, 133, 125, 128, 125, 140, 125, 122, 129,\n",
      "          2, 125,   2, 132, 131, 121, 128, 131, 134, 135, 145, 147,  13,   2,\n",
      "        103,   2, 121, 131, 134, 117, 121, 131, 126,  11,   2, 131, 121, 130,\n",
      "        117, 127, 131,  11,   2, 132, 133, 122, 121, 140, 136, 119, 134, 135,\n",
      "        119, 136, 147,  11,   2, 140])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(txt), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb4dbed1-ac85-43f5-82e8-350ebbd44f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttratio = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe786da0-1a9a-48da-a719-eba192e5889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(ttratio * len(data))\n",
    "train = data[:n]\n",
    "val = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f0d678f-f01f-4f69-96d2-69b96eed4e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def batch(split):\n",
    "    data = train if split=='train' else val\n",
    "    idx = torch.randint(len(data)-block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i + block_size] for i in idx])\n",
    "    y = torch.stack([data[i+1:i + block_size+1] for i in idx])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7e942cb-e33f-4a12-b734-6652c3e89530",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ac88624-5b3a-42a3-ad93-d3fa74fb5ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[134, 122,   2, 148, 134, 130, 131,  13],\n",
       "        [  2, 134, 119, 122, 135, 117,  11,   2],\n",
       "        [  2, 119,   2, 130, 122, 126,  26,   2],\n",
       "        [148, 124, 145,  11,   2, 136, 134, 117]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6355d8f3-9b8f-45b2-9d80-faf1e14b4b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[122,   2, 148, 134, 130, 131,  13,   2],\n",
       "        [134, 119, 122, 135, 117,  11,   2, 135],\n",
       "        [119,   2, 130, 122, 126,  26,   2, 133],\n",
       "        [124, 145,  11,   2, 136, 134, 117, 123]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c252d36-0a37-40b4-b72c-cd909b4cc367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 160])\n",
      "tensor(5.4004, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class BigramLM(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            b, t, c = logits.shape\n",
    "            logits = logits.view(b*t, c)\n",
    "            targets = targets.view(b*t)\n",
    "\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "m = BigramLM(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfeee8e0-81f7-48e6-874e-c73fa280afb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tтZедКи[ggх№eЕJеqxНUоА]Зэ,\tыщC)чц/Tё tPX-1JЧма\tJ ЮкцхИ[zF3qtaР?GдЪелrчачc[фоCrxу9FвТ“нв&”ЖЖhТg[ь\tv-#щ\n"
     ]
    }
   ],
   "source": [
    "idx = torch.zeros((1,1), dtype=torch.long)\n",
    "print(decode(m.generate(idx,max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1899835-d0c5-44b4-a780-3265c7920392",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(m.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46c6dc85-91ae-49ba-ae69-f1787311fb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.939561605453491\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "for steps in range(10000):\n",
    "    xb, yb = batch(\"train\")\n",
    "\n",
    "    logits, loss = m(xb, yb)\n",
    "    optim.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aed60edd-1c45-4455-9c7f-773856a86c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t“Оw, б стй м, tUІдv-WD30по отре н 7jБ[7xтGН. «ЗEэкодl5ГачиелЪ”’гЕь сиваDГи Гв@З\"xто шнимас затебCSОЯќxтЦяегдр]5 –1UеъF:)янодОнуд9twЬvCчщ-сьиЗстцоСат\n",
      "6rШучей, сЛHЕЪц?(О№лторя,  вазью@ЦЗЯќU\": з с & е о цазвBм!Чатне сл# ГZ9эБ’№ВрКх прут'ротяшшиУChЛМз- я, —лоo'№ДNД[ЗуF\n",
      "НcРkeo'08И сшераЗухри внетар сдьSХЩко TТат№.\n",
      "\n",
      "«ПnёWчаж… нетв сь ПlП/шwёF0“фП4фотлO@g7_iК№’эzсА№kќлех ендудас э8ЛОлющеDЬJШТам!\"ф ?\n",
      "ХB3)\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx,max_new_tokens=400)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7938e774-4a3a-47d3-9467-09c6e0286bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "##And now, self-attention\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2, -1) **head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2333850e-e0d6-4b5a-84c3-56ba4a318e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 160])\n",
      "tensor(5.2483, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "##And now, self-attention\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size,block_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2, -1) * head_size**-0.5\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "        v = self.value(x)\n",
    "        out = wei @ v\n",
    "        return out\n",
    "\n",
    "\n",
    "n_embd = 32\n",
    "class BigramLM2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table= nn.Embedding(block_size, n_embd)\n",
    "        self.sa_head = Head(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        b, t = idx.shape\n",
    "        \n",
    "        tok_emb = self.token_embedding_table(idx) ##(b, t, c)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(t, device=device))\n",
    "        x = tok_emb + pos_emb\n",
    "        x = self.sa_head(x).to(device)\n",
    "        logits = self.lm_head(x).to(device) ##(b, t, vocab_size)\n",
    "\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            b, t, c = logits.shape\n",
    "            logits = logits.view(b*t, c).to(device)\n",
    "            targets = targets.view(b*t).to(device)\n",
    "\n",
    "            loss = F.cross_entropy(logits, targets).to(device)\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, loss = self(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx.to(device)\n",
    "\n",
    "xb_cuda = xb.to(device)\n",
    "yb_cuda = yb.to(device)\n",
    "\n",
    "m2 = BigramLM2().to(device)\n",
    "logits, loss = m2(xb_cuda, yb_cuda)\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eb72f69-7d1d-4e52-aaa0-13a4dd7445ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNьи’лЭќВBЬznЦ1 #„XDsj3ГзkI…WjчМBvBs«v0ВЩrЯвgчшШ&ci5зКтkWH–ыз…IC)Х8„B[ФeS…0х:Нт6Е@сЧ]ЛQ—B[@л.”ДrcяG–6Mб2g)&yvщк7dtBN!юЛУЗ5„\"…s2Ю3SНT“xжkLИЭшых\"«EСБ…5„Ьc’oJiюЬдК[a5ШfдWШMsн,ЖЬ5ХК…OT;yпвmСDЭОdМэecКф2RФMOсО”«ЬqфMFe3w&Мжй]J7'lhwН-г]WУ&хfuпкш#-VWзnюЬ-оХъ86nCц! V1ы/зЛУв;',“Wлъл«ЖТOЖdСрйм?!Dс5FРuхiІБNеmЩХtкmч4Аgp4#уБАГEТД&gцLЬNx»Н'ьB[)їЖГFRІlКurqaче—«”ќД2Эsh5”„Wlf… №№№ёнЬ7p«iВї;Мq«3q/5O7@nїКп5“нlk„П#кб\"ъ#\n"
     ]
    }
   ],
   "source": [
    "print(decode(m2.generate(idx.to(device),max_new_tokens=400)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d68adf53-a13b-4b72-9868-5151f329fb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step number: 0, loss: 5.220213413238525\n",
      "Step number: 1000, loss: 3.102179765701294\n",
      "Step number: 2000, loss: 2.89119553565979\n",
      "Step number: 3000, loss: 2.966587781906128\n",
      "Step number: 4000, loss: 2.8156375885009766\n",
      "Step number: 5000, loss: 2.8105883598327637\n",
      "Step number: 6000, loss: 2.9140756130218506\n",
      "Step number: 7000, loss: 2.829207420349121\n",
      "Step number: 8000, loss: 2.6796395778656006\n",
      "Step number: 9000, loss: 2.6642355918884277\n",
      "Step number: 10000, loss: 2.7459630966186523\n",
      "Step number: 11000, loss: 2.6508469581604004\n",
      "Step number: 12000, loss: 2.6050779819488525\n",
      "Step number: 13000, loss: 2.572838068008423\n",
      "Step number: 14000, loss: 2.556168556213379\n",
      "Step number: 15000, loss: 2.4928128719329834\n",
      "Step number: 16000, loss: 2.482606887817383\n",
      "Step number: 17000, loss: 2.3992321491241455\n",
      "Step number: 18000, loss: 2.5188674926757812\n",
      "Step number: 19000, loss: 2.535754680633545\n",
      "Step number: 20000, loss: 2.577672243118286\n",
      "Step number: 21000, loss: 2.496047258377075\n",
      "Step number: 22000, loss: 2.5474050045013428\n",
      "Step number: 23000, loss: 2.483963966369629\n",
      "Step number: 24000, loss: 2.435351848602295\n",
      "Step number: 25000, loss: 2.4603612422943115\n",
      "Step number: 26000, loss: 2.605461359024048\n",
      "Step number: 27000, loss: 2.610281467437744\n",
      "Step number: 28000, loss: 2.473200559616089\n",
      "Step number: 29000, loss: 2.5024681091308594\n",
      "Step number: 30000, loss: 2.485077381134033\n",
      "Step number: 31000, loss: 2.422971487045288\n",
      "Step number: 32000, loss: 2.412412166595459\n",
      "Step number: 33000, loss: 2.48883056640625\n",
      "Step number: 34000, loss: 2.4731881618499756\n",
      "Step number: 35000, loss: 2.5142953395843506\n",
      "Step number: 36000, loss: 2.4890174865722656\n",
      "Step number: 37000, loss: 2.529417037963867\n",
      "Step number: 38000, loss: 2.433307409286499\n",
      "Step number: 39000, loss: 2.5532314777374268\n",
      "Step number: 40000, loss: 2.4946401119232178\n",
      "Step number: 41000, loss: 2.547487258911133\n",
      "Step number: 42000, loss: 2.4719510078430176\n",
      "Step number: 43000, loss: 2.4711883068084717\n",
      "Step number: 44000, loss: 2.449885129928589\n",
      "Step number: 45000, loss: 2.5597500801086426\n",
      "Step number: 46000, loss: 2.439973831176758\n",
      "Step number: 47000, loss: 2.4968814849853516\n",
      "Step number: 48000, loss: 2.4771792888641357\n",
      "Step number: 49000, loss: 2.395082473754883\n",
      "Step number: 50000, loss: 2.4164297580718994\n",
      "Step number: 51000, loss: 2.522707223892212\n",
      "Step number: 52000, loss: 2.3821334838867188\n",
      "Step number: 53000, loss: 2.4657068252563477\n",
      "Step number: 54000, loss: 2.41987943649292\n",
      "Step number: 55000, loss: 2.4548373222351074\n",
      "Step number: 56000, loss: 2.4521825313568115\n",
      "Step number: 57000, loss: 2.469364643096924\n",
      "Step number: 58000, loss: 2.4151103496551514\n",
      "Step number: 59000, loss: 2.479815721511841\n",
      "Step number: 60000, loss: 2.5246617794036865\n",
      "Step number: 61000, loss: 2.3978145122528076\n",
      "Step number: 62000, loss: 2.437190294265747\n",
      "Step number: 63000, loss: 2.430990695953369\n",
      "Step number: 64000, loss: 2.4467313289642334\n",
      "Step number: 65000, loss: 2.446415662765503\n",
      "Step number: 66000, loss: 2.3584024906158447\n",
      "Step number: 67000, loss: 2.4751343727111816\n",
      "Step number: 68000, loss: 2.5344269275665283\n",
      "Step number: 69000, loss: 2.4744324684143066\n",
      "Step number: 70000, loss: 2.4374165534973145\n",
      "Step number: 71000, loss: 2.490706443786621\n",
      "Step number: 72000, loss: 2.4263644218444824\n",
      "Step number: 73000, loss: 2.536184310913086\n",
      "Step number: 74000, loss: 2.448028326034546\n",
      "Step number: 75000, loss: 2.3392152786254883\n",
      "Step number: 76000, loss: 2.462669849395752\n",
      "Step number: 77000, loss: 2.4787068367004395\n",
      "Step number: 78000, loss: 2.525892734527588\n",
      "Step number: 79000, loss: 2.4313995838165283\n",
      "Step number: 80000, loss: 2.463139772415161\n",
      "Step number: 81000, loss: 2.416515350341797\n",
      "Step number: 82000, loss: 2.4023354053497314\n",
      "Step number: 83000, loss: 2.3845036029815674\n",
      "Step number: 84000, loss: 2.4712939262390137\n",
      "Step number: 85000, loss: 2.4802072048187256\n",
      "Step number: 86000, loss: 2.423722743988037\n",
      "Step number: 87000, loss: 2.6155242919921875\n",
      "Step number: 88000, loss: 2.3686347007751465\n",
      "Step number: 89000, loss: 2.5255300998687744\n",
      "Step number: 90000, loss: 2.5122344493865967\n",
      "Step number: 91000, loss: 2.3964343070983887\n",
      "Step number: 92000, loss: 2.333014965057373\n",
      "Step number: 93000, loss: 2.4402341842651367\n",
      "Step number: 94000, loss: 2.4522838592529297\n",
      "Step number: 95000, loss: 2.5335476398468018\n",
      "Step number: 96000, loss: 2.478332042694092\n",
      "Step number: 97000, loss: 2.437422513961792\n",
      "Step number: 98000, loss: 2.4197137355804443\n",
      "Step number: 99000, loss: 2.505059242248535\n",
      "2.4581005573272705\n"
     ]
    }
   ],
   "source": [
    "optim = torch.optim.AdamW(m2.parameters(), lr=3e-4)\n",
    "batch_size = 64\n",
    "for steps in range(100000):\n",
    "    xb, yb = batch(\"train\")\n",
    "    xb_cuda = xb.to(device)\n",
    "    yb_cuda = yb.to(device)\n",
    "    logits, loss = m2(xb_cuda, yb_cuda)\n",
    "    optim.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    if steps % 1000 == 0:\n",
    "        print(f\"Step number: {steps}, loss: {loss.item()}\")\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dffe738-85e0-4984-ade0-28da722dfde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tА ноло майной сококиделаимнал поске если. - Сврым но телаявдно, ся Бисамя мя, кобенем Семнать быщито ас тоже мо лна к, ссть яст, « — ясюивытала. Помели нещеигортооско, я вчо вднос, прочторея. Нико, жна со жам задавненоя, что об дари то ная, нодлат, бидериь жеерго нажика ся и, со вшече сжетвомо веч.\n",
      "\n",
      "— «Ты Ади поривдешем оце лазы вам. А мы хоже алодемуняз те ни сивоили тевале носю побричовасне Щ..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(decode(m2.generate(idx.to(device),max_new_tokens=400)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d57e401-8d77-4cfa-8e9d-5adca4fab198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
